from selenium import webdriver
from bs4 import BeautifulSoup
import time
import os
import requests

print("="*80)
print(" pixbay 사이트 이미지를 검색하여 수집하는 크롤러입니다")
print("="*80)
keyword = input("1. 크롤링할 이미지의 키워드는 무엇입니까?: ")
img_count = int(input("2. 크롤링 할 건수는 몇건입니까?:"))
folder = input("3. 파일이 저장될 경로만 쓰세요(예: c:/temp: ")

driver = webdriver.Chrome()

session = requests.Session()
session.headers.update({'User-Agent': 'Mozilla/5.0'})

img_number = 1
page_num = 1
scroll_time = 4

while img_number <= img_count:
    url = f"https://pixabay.com/ko/images/search/{keyword}/?pagi={page_num}"
    driver.get(url)
    time.sleep(4) 

    soup = BeautifulSoup(driver.page_source, 'html.parser')

    img_tags = soup.select('img')

    for img_tag in img_tags:
        img_url = img_tag.get('src')

        if img_url and img_url.startswith('https://cdn.pixabay.com/photo'):
            print(f"{img_number}/{img_count} 수집 완료")
            save_path = os.path.join(folder, f'{img_number}.jpg')
            
            try:
                response = session.get(img_url, stream=True)
                response.raise_for_status()
                with open(save_path, "wb") as f:
                    for chunk in response.iter_content(chunk_size=1024):
                        if chunk:
                            f.write(chunk)
                img_number += 1

                if img_number > img_count:
                    break
            except:
                print("이미지 다운로드에 실패하였습니다. ")

    driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
    time.sleep(scroll_time)
    
    page_num += 1

print(f"총 {img_count} 개의 이미지를 다운로드했습니다.")
driver.quit()
